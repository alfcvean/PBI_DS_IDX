{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1717ed-8c3b-47b7-a596-e77c4281f42b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.artist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#import xgboost as xgb\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#import lightgbm as lgb\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colorbar.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\collections.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, cm, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, _docstring,\n\u001b[0;32m     21\u001b[0m                hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\lines.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, _docstring\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Artist, allow_rasterization\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m     _to_unmasked_float_array, ls_mapper, ls_mapper_r, STEP_LOOKUP_MAP)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmarkers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MarkerStyle\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.artist'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "#import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "#from prettytable import PrettyTable\n",
    "from sklearn.metrics import roc_curve,auc, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.metrics import fbeta_score\n",
    "from imblearn import over_sampling\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392f379",
   "metadata": {},
   "source": [
    "# Data Exploration & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce755f-fc30-438c-8ebd-2617e4a48d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_data_2007_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf52c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a1cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Columns :\", df.shape[1])\n",
    "print(\"Total Rows :\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94619b1",
   "metadata": {},
   "source": [
    "Data pinjaman memiliki dimensi awal sebesar **466285 rows** dan **75 columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5a161",
   "metadata": {},
   "source": [
    "## Duplicate Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb086a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True)\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a0373",
   "metadata": {},
   "source": [
    "Data tidak memiliki row yang duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3a63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d82c5",
   "metadata": {},
   "source": [
    "## Null Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ea6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_null = df_copy.isnull().sum() \n",
    "perc_null = df_copy.isnull().sum() * 100/ len(df) \n",
    "\n",
    "\n",
    "df_null_val = pd.DataFrame({'Total Null': total_null, 'Percentage Null': perc_null}) \n",
    "df_null_val.sort_values('Percentage Null', ascending = False,inplace = True) \n",
    "null_value = df_null_val[df_null_val['Percentage Null']>0].reset_index() \n",
    "null_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a40f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null di atas 40% karena dapat merusak data\n",
    "col_null40 = df_null_val.loc[df_null_val['Percentage Null']> 40].index.tolist()\n",
    "df_copy.drop(columns=col_null40, inplace = True) \n",
    "\n",
    "# null di kolom numerical diganti dengan Median\n",
    "for col in df_copy.select_dtypes(exclude='object'):\n",
    "    df_copy[col] = df_copy[col].fillna(df_copy[col].median())\n",
    "\n",
    "# null di kolom categorical diganti dengan Modus\n",
    "for col in df_copy.select_dtypes(include='object'):\n",
    "    df_copy[col] = df_copy[col].fillna(df_copy[col].mode().iloc[0])\n",
    "    \n",
    "df_copy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7024b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gabungkan kategori\n",
    "df_copy['loan_status'] = df_copy['loan_status'].replace({\n",
    "    'Does not meet the credit policy. Status:Fully Paid': 'Fully Paid',\n",
    "    'Does not meet the credit policy. Status:Charged Off': 'Charged Off'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['term'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0685e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hanya mengambil 3 karakter awal dari term\n",
    "df_copy['term'] = df_copy['term'].apply(lambda term: int(term[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f12034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengatur kolom bertipe datetime\n",
    "df_copy['earliest_cr_line'] = pd.to_datetime(df_copy['earliest_cr_line'], format = '%b-%y') \n",
    "df_copy['last_credit_pull_d'] = pd.to_datetime(df_copy['last_credit_pull_d'], format = '%b-%y') \n",
    "df_copy['last_pymnt_d'] = pd.to_datetime(df_copy['last_pymnt_d'], format = '%b-%y') \n",
    "\n",
    "df_copy['earliest_cr_line'] = round(pd.to_numeric((pd.to_datetime('2016-03-01') - df_copy['earliest_cr_line']) / np.timedelta64(30, 'D'))) \n",
    "df_copy['last_credit_pull_d'] = round(pd.to_numeric((pd.to_datetime('2016-03-01') - df_copy['last_credit_pull_d']) / np.timedelta64(30, 'D'))) \n",
    "df_copy['last_pymnt_d'] = round(pd.to_numeric((pd.to_datetime('2016-03-01') - df_copy['last_pymnt_d']) / np.timedelta64(30, 'D'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghapus kolom yang tidak dibutuhkan\n",
    "df_copy.drop(['Unnamed: 0', 'policy_code','application_type','title', 'url', 'addr_state','sub_grade','member_id', 'emp_title','pymnt_plan','issue_d', 'zip_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_list = [] \n",
    "for col in df_copy.columns: \n",
    "    unique_list.append([col, df_copy[col].nunique(), df_copy[col].unique()[:5]]) \n",
    "\n",
    "unique_val = pd.DataFrame(data=unique_list, columns='Feature,Unique,Unique Sample'.split(\",\"))\n",
    "unique_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb3a16c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b3fe7",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = df_copy.select_dtypes(include=np.number).columns\n",
    "categorical = df_copy.select_dtypes(exclude=np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[numerical].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy[categorical].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f385038",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,25)) \n",
    "sns.heatmap(df_copy[numerical].corr(), cmap='viridis', annot=True, fmt='.2f') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05f4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mencari kolom yang memiliki korelasi tinggi\n",
    "correlation = df_copy[numerical].corr().abs() \n",
    "corr_list = correlation.where(np.triu(np.ones(correlation.shape), k=1).astype(bool)) \n",
    "high_corr = [column for column in corr_list.columns if any(corr_list[column] > 0.7)]\n",
    "high_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70693745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(high_corr, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e2abaf",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate = df_copy.select_dtypes(include=[np.float64,np.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displot untuk melihat distribusi tiap kolom numerical\n",
    "plt.figure(figsize=(30, 30))\n",
    "for i in range(0, 21):\n",
    "    plt.subplot(7, 5, i+1)\n",
    "    sns.distplot(univariate.iloc[:,i], color='green')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446e6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot untuk melihat kemungkinan outliers tiap kolom numerical\n",
    "plt.figure(figsize=(30, 30))\n",
    "for i in range(0, 21):\n",
    "    plt.subplot(7, 5, i+1)\n",
    "    sns.boxplot(univariate.iloc[:,i], color='green', orient='v')\n",
    "    plt.xlabel(univariate.columns[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efaa7cb",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41294a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menerapkan transformasi Yeo-Johnson\n",
    "def apply_yeojohnson(df, column):\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    # Hanya menerapkan transformasi pada kolom numerik\n",
    "    transformed_data = pt.fit_transform(df[[column]])\n",
    "    df[column] = transformed_data\n",
    "    return df\n",
    "\n",
    "# Salinan dataset untuk menyimpan hasil transformasi\n",
    "df_transformed = df_copy.copy()\n",
    "\n",
    "# Menerapkan transformasi Yeo-Johnson pada setiap kolom numerik di X_test\n",
    "for column in univariate:\n",
    "    df_transformed = apply_yeojohnson(df_transformed, column)\n",
    "\n",
    "# Fungsi untuk membuat histogram dan boxplot\n",
    "def plot_transformation(transformed, column):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    # Histogram Transformed\n",
    "    sns.histplot(transformed[column], kde=True, ax=ax[0], color='green')\n",
    "    ax[0].set_title(f'Transformed (Yeo-Johnson) - {column}')\n",
    "    ax[0].set_xlabel(f'log_{column}')\n",
    "\n",
    "    # Boxplot Transformed\n",
    "    sns.boxplot(x=transformed[column], ax=ax[1], color='green')\n",
    "    ax[1].set_title(f'Transformed (Yeo-Johnson) - {column}')\n",
    "    ax[1].set_xlabel(f'log_{column}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Menampilkan plot untuk setiap kolom yang telah ditransformasi\n",
    "for column in univariate:\n",
    "    plot_transformation(df_transformed, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff44419a",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eceeecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = df_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_status_counts = eda['loan_status'].value_counts().sort_values(ascending=True)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 7)) \n",
    "loan_status_counts.plot(kind='barh', color='green', width=0.8) \n",
    "\n",
    "# Menambahkan judul dan label sumbu\n",
    "plt.title('Jumlah Pengajuan berdasarkan Loan Status\\n', fontsize=14) \n",
    "plt.ylabel('Loan Status') \n",
    "plt.xlabel('Applicants')\n",
    "\n",
    "for i, v in enumerate(loan_status_counts):\n",
    "    plt.text(v + 3, i + .25, str(v), color='black')\n",
    "\n",
    "# Menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd10071",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda['loan_status'] = eda['loan_status'].astype(str)\n",
    "eda['term'] = eda['term'].astype(str)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "fig = sns.countplot(data=eda, x='loan_status', hue='term', palette='viridis')\n",
    "\n",
    "plt.title('Loan Status by Term\\n', fontsize=12)\n",
    "plt.xlabel('\\nLoan Status', fontsize=12)\n",
    "plt.ylabel('Count\\n', fontsize=12)\n",
    "\n",
    "for p in fig.patches:\n",
    "    height = p.get_height() \n",
    "    if height > 0: \n",
    "        fig.annotate(f'{int(height)}',\n",
    "                     (p.get_x() + p.get_width() / 2, height),\n",
    "                     ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "fig = sns.countplot(data=eda, x='loan_status', hue='verification_status', palette='viridis')\n",
    "\n",
    "plt.title('Loan Status by Verification Status\\n', fontsize=12)\n",
    "plt.xlabel('\\nLoan Status', fontsize=12)\n",
    "plt.ylabel('Count\\n', fontsize=12)\n",
    "\n",
    "for p in fig.patches:\n",
    "    height = p.get_height() \n",
    "    if height > 0: \n",
    "        fig.annotate(f'{int(height)}',\n",
    "                     (p.get_x() + p.get_width() / 2, height),\n",
    "                     ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06319975",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef20ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature = df_transformed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memberikan label pada target\n",
    "df_feature['binary_loan_status'] = df_feature['loan_status'].apply(\n",
    "    lambda x: 1 if x in ['Fully Paid', 'Current', 'In Grace Period'] else 0 # label 1 jika berstatus GOOD dan 0 jika berstatus BAD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843c5437",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cef944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop feature categorical dengan unique value yang terlalu banyak\n",
    "df_feature.drop(['emp_length','purpose'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in ['grade', 'verification_status', 'home_ownership', 'initial_list_status']:\n",
    "  onehots = pd.get_dummies(df_feature[cat], prefix=cat)\n",
    "  df_feature = df_feature.join(onehots)\n",
    "\n",
    "df_feature = df_feature.drop(columns=['grade', 'verification_status', 'home_ownership', 'initial_list_status'], axis =1)\n",
    "\n",
    "# mengubah hasil OHE menjadi int\n",
    "boolean_cols = df_feature.select_dtypes(include=['bool']).columns\n",
    "df_feature[boolean_cols] = df_feature[boolean_cols].astype(int)\n",
    "\n",
    "df_feature.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59cd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Rows :\", df_feature.shape[0])\n",
    "print(\"Total Features :\", df_feature.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d588298",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eac30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_feature.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467f3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop(labels=['binary_loan_status','loan_status'],axis=1)\n",
    "y = df_final[['binary_loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f3426",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d33ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = over_sampling.SMOTE(sampling_strategy=1).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c504889",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a443f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk evaluasi model \n",
    "\n",
    "def model_evaluation(y_true, y_pred, y_pred_proba, model_name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    f2 = fbeta_score(y_true, y_pred, beta=2.0)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "    \n",
    "    results = pd.DataFrame([[model_name, acc, prec, rec, f1, f2, auc]],\n",
    "                       columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\",\n",
    "                                \"F1 Score\", \"F2 Score\", \"roc_auc_score\"])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d916ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untuk cek overfitting vs underfitting atau best fit\n",
    "def check_model_fit(classifier, X_train, X_val, y_train, y_val, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Membandingkan performa model pada data training dan validation\n",
    "    untuk mendeteksi overfitting/underfitting\n",
    "    \"\"\"\n",
    "    # Prediksi pada data training\n",
    "    y_train_pred = classifier.predict(X_train)\n",
    "    y_train_pred_proba = classifier.predict_proba(X_train)\n",
    "    \n",
    "    # Prediksi pada data validation\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "    y_test_pred_proba = classifier.predict_proba(X_test)\n",
    "    \n",
    "    # Metrics untuk training\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    train_f2 = fbeta_score(y_train, y_train_pred, beta=2.0)\n",
    "    train_roc_auc = roc_auc_score(y_train, y_train_pred_proba[:, 1])\n",
    "\n",
    "    # Metrics untuk validation\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "    test_f2 = fbeta_score(y_test, y_test_pred, beta=2.0)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_test_pred_proba[:, 1])\n",
    "    \n",
    "\n",
    "    # Membuat DataFrame perbandingan\n",
    "    comparison = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'ROC AUC'],\n",
    "        'Training': [train_accuracy, train_precision, train_recall, train_f1, train_f2, train_roc_auc],\n",
    "        'Validation': [test_accuracy, test_precision, test_recall, test_f1, test_f2, test_roc_auc],\n",
    "        'Difference': [train_accuracy - test_accuracy, \n",
    "                      train_precision - test_precision,\n",
    "                      train_recall - test_recall,\n",
    "                      train_f1 - test_f1,\n",
    "                      train_f2 - test_f2,\n",
    "                      train_roc_auc - test_roc_auc]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nModel Fit Analysis for {model_name}:\")\n",
    "    print(comparison.round(4))\n",
    "    \n",
    "    # Analisis overfitting/underfitting\n",
    "    avg_diff = comparison['Difference'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, X_test, y_test, title):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Greens', annot_kws={\"fontsize\":12}, ax=ax)\n",
    "\n",
    "    # setting title and axis labels\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    ax.set_xlabel('Predicted Labels', fontsize=12)\n",
    "    ax.set_ylabel('True Labels', fontsize=12)\n",
    "    ax.set_title('Confusion Matrix ' + title, fontsize=14)\n",
    "    ax.xaxis.set_ticklabels(['Bad', 'Good'])\n",
    "    ax.yaxis.set_ticklabels(['Bad', 'Good'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95218016",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b06c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_lr = LogisticRegression()\n",
    "classifier_lr.fit(X_train, y_train)\n",
    "y_pred = classifier_lr.predict(X_test)\n",
    "y_pred_proba = classifier_lr.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "results_lr = model_evaluation(y_test, y_pred, y_pred_proba, \"Logistic Regression\")\n",
    "results_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_fit(\n",
    "    classifier_lr,\n",
    "    X_train,  # Data training\n",
    "    X_test,   # Data validation\n",
    "    y_train,  # Label training\n",
    "    y_test,   # Label validation\n",
    "    \"Logistic Regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(classifier_lr, X_test, y_test, title='Logistic Regression')\n",
    "classifier_lr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa6e1ef",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b73fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dt = DecisionTreeClassifier()\n",
    "classifier_dt.fit(X_train, y_train)\n",
    "y_pred = classifier_dt.predict(X_test)\n",
    "y_pred_proba = classifier_dt.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "results_dt = model_evaluation(y_test, y_pred, y_pred_proba, \"Decision Tree\")\n",
    "results_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c34e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_fit(\n",
    "    classifier_dt,\n",
    "    X_train,  # Data training\n",
    "    X_test,   # Data validation\n",
    "    y_train,  # Label training\n",
    "    y_test,   # Label validation\n",
    "    \"Descision Tree\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80289353",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7691157",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf = RandomForestClassifier()\n",
    "classifier_rf.fit(X_train, y_train)\n",
    "y_pred = classifier_rf.predict(X_test)\n",
    "y_pred_proba = classifier_rf.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "results_rf = model_evaluation(y_test, y_pred, y_pred_proba, \"Random Forest\")\n",
    "results_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f92e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_fit(\n",
    "    classifier_rf,\n",
    "    X_train,  # Data training\n",
    "    X_test,   # Data validation\n",
    "    y_train,  # Label training\n",
    "    y_test,   # Label validation\n",
    "    \"Random Forest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1fea9",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618505f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_lgbm = LGBMClassifier()\n",
    "classifier_lgbm.fit(X_train, y_train)\n",
    "y_pred = classifier_lgbm.predict(X_test)\n",
    "y_pred_proba = classifier_lgbm.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "results_lgbm = model_evaluation(y_test, y_pred, y_pred_proba, \"LightGBM\")\n",
    "results_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec21fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_fit(\n",
    "    classifier_lgbm,\n",
    "    X_train,  # Data training\n",
    "    X_test,   # Data validation\n",
    "    y_train,  # Label training\n",
    "    y_test,   # Label validation\n",
    "    \"LightGBM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524d5ec",
   "metadata": {},
   "source": [
    "## Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68d76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_ab = AdaBoostClassifier()\n",
    "classifier_ab.fit(X_train, y_train)\n",
    "y_pred = classifier_ab.predict(X_test)\n",
    "y_pred_proba = classifier_ab.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "results_ab = model_evaluation(y_test, y_pred, y_pred_proba, \"Ada Boost\")\n",
    "results_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7946db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_fit(\n",
    "    classifier_ab,\n",
    "    X_train,  # Data training\n",
    "    X_test,   # Data validation\n",
    "    y_train,  # Label training\n",
    "    y_test,   # Label validation\n",
    "    \"Ada Boost\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029579dd",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be8b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_xgb =  XGBClassifier()\n",
    "classifier_xgb.fit(X_train, y_train)\n",
    "y_pred = classifier_xgb.predict(X_test)\n",
    "y_pred_proba = classifier_xgb.predict_proba(X_test)\n",
    "\n",
    "# Evaluasi\n",
    "results_xgb = model_evaluation(y_test, y_pred, y_pred_proba, \"Ada Boost\")\n",
    "results_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d38b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_model_fit(\n",
    "    classifier_xgb,\n",
    "    X_train,  # Data training\n",
    "    X_test,   # Data validation\n",
    "    y_train,  # Label training\n",
    "    y_test,   # Label validation\n",
    "    \"XGBoost\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
